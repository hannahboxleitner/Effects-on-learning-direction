---
title: "Reproducibility study: Effects of Learning Direction in Retrieval Practice on EFL Vocabulary Learning"
subtitle: "Based on data from Terai et al. (2021)"
authors: "Hannah Boxleitner, Beyhan Aliy"
date: last-modified
format:
  html:
    number-sections: true
    embed-resources: true
    fig-dpi: 300
editor: 
  markdown: 
    wrap: 72
---

# Chapter overview

This chapter is based on data published in:

-   Terai, Masato, Junko Yamashita, and Kelly E. Pasich. 2021. EFFECTS
    OF LEARNING DIRECTION IN RETRIEVAL PRACTICE ON EFL VOCABULARY
    LEARNING. Studies in Second Language Acquisition 43(5): 1116–1137.
    <https://doi.org/10.1017/S0272263121000346>.

This chapter will introduce the application of R in Second Language
Acquisition research, using data from Terai et al. (2021). We will go
through the entire data analysis pipeline, from importing the data
(chapter ???) to running logistic regression models and visualizing
results with it. By the end of this chapter, it should become clear how
to conduct and interpret mixed-effects logistics regression models in R
for experimental data.

# Introducing the study

In this chapter, we attempt to reproduce the results of a linguistics
study by Terai et al. (2021). The study focuses on learning directions
in pair-associated vocabulary learning: L2 to L1, where L2 words are
used as stimuli and responses are given in L1, vs. L1 to L2. Opposed to
studying practices, where both a target and the answer are
simultaneously presented, pair-associated learning includes *retrieval*.
Retrieval is defined as the process of accessing stored information and
plays a crucial role in retaining a learned word in memory **(p.
1116-1117 - Literaturangabe?)**. Previous findings regarding the
efficacy of the two types of learning directions are inconsistent. The
study focuses on the relationship between L2 proficiency and the
effectiveness of the two learning directions in paired-associate
learning in L2 vocabulary acquisition, and follows two research
questions: 1. Which learning direction is more effective for vocabulary
acquisition, L1 to L2 learning or L2 to L1 learning? 2. How does L2
proficiency influence the effects of L2 to L1 and L1 to L2 learning?

Therefore, the authors established the hypotheses that there is no
significant difference between the two learning directions and that the
effect of learning direction depends on the learner’s L2 proficiency
**(p. 1121-1122).**

# Retrieving the authors' data

We will use the authors' original data for our reproduction, which they
have made openly accessible on IRIS, a free database for language
research:

-   [Terai, M., Yamashita, J. & Pasich, K. E. (2021). Effects of
    Learning Direction in Retrieval Practice on EFL Vocabulary Learning.
    Studies in Second Language Acquisition. 43(5).
    1116–1137)](https://www.iris-database.org/search/?s_publicationAPAInlineReference=Terai%20et%20al.%20(2021))

In this particular case, you cannot just access the data, but also the
authors' R code. Our further reproduction will use this R code to
investigate and interpret the statistical analysis and results presented
in the paper.

The dataset (dataset1_ssla_20210313.csv) contains data for each
participant and item. Each row includes:

-   Answer: whether the participant gave the correct answer (1 =
    correct, 0 = incorrect)

-   Test: test type (L1 Production or L2 Production)

-   Condition: learning direction (L2-\>L1 or L1-\>L2)

-   ID: participant identifier

-   ItemID: item (word) identifier

-   Vocab: vocabulary test score (L2 proficiency)

-   *more ( L2 frequency?, length, syllables, etc.?)? -\> why not
    included?*

# Importing the data

Before importing the dataset and starting on our project, we need to
load all the packages that we will need. Some of these packages may have
to installed first **(maybe include textbook reference 13.10)**.

```{r}
#| label: setup
#| warning: false

# This chunk loads necessary libraries.

# Load libraries
library(here)
library(tidyverse)

```

Next, we can import the data. In contrast to the authors' approach in
their code, we used the here package for importing the data. This
package creates paths relative to the top-level directory and therefore
makes it easier to reference files regardless of how they are organized
inside a project.

```{r}
VocabularyA_L1production <- read.csv(file = here("data", "vocaA_L1pro_20210313.csv"))
VocabularyA_L2production <- read.csv(file = here("data", "vocaA_L2pro_20210313.csv"))
VocabularyB_L1production <- read.csv(file = here("data", "vocaB_L1pro_20210313.csv"))
VocabularyB_L2production <- read.csv(file = here("data", "vocaB_L2pro_20210313.csv"))

#First, we will load the dataset
dat<-read.csv(file = here("data", "dataset1_ssla_20210313.csv"), header=T)

#Then, we need to convert the categorical variables we have to factors using the function as.factor()
dat$Test<-as.factor(dat$Test)
dat$Condition<-as.factor(dat$Condition)

#Next, we will contrast the coding (-0.5 vs. +0.5) for categorical predictors.
c<-contr.treatment(2)
my.coding<-matrix(rep(1/2,2,ncol=1))
my.simple<-c-my.coding
print(my.simple)

contrasts(dat$Test)<-my.simple
contrasts(dat$Condition)<-my.simple

#And standardize vocabulary scores (centered and scaled)
dat$s.vocab<-scale(dat$Vocab)

##All these steps set up the dataset for modeling. Converting variables to factors and coding them with contrast ensures that they are interpreted correctly in the regression. Scaling the vocabulary scores helps with interaction terms.
```

# Descriptive statistics

Before we dive into the descriptive statistics conducted in this study,
we need to explain that one part of it will not be reproduced. While
descriptive statistics about the participants (age, years of learning
etc.) are mentioned in the paper by Terai et al., the data to reproduce
these findings cannot be found. It is neither part of the data set
accessible on IRIS, nor does it come up anywhere in the authors' R code.

# Descriptive statistics of the tests and reliability testing

In this chapter, we will attempt to reproduce the authors' descriptive
statistics regarding the two types of post tests and calculate
Cronbach's α to test reliability.

## Reliability analysis

```{r}
# Vocabulary A (L1 production)

# In this chunk, we conduct a reliability analysis for Vocabulary A scores of the L1 production dataset. For this to work, the psych package has to be installed and loaded:
# install.packages("psych", dependencies = TRUE)

library(psych)

# We apply the alpha() function for reliability testing.

alpha(VocabularyA_L1production[,-1], warnings=FALSE)

```

```{r}
# Vocabulary A (L2 production)

# The same function is used to conduct a reliability analysis for Vocabulary A of the L2 participants.

alpha(VocabularyA_L2production[,-1], warnings=FALSE)

```

```{r}
# Vocabulary B (L1 production)

# With Vocabulary B, we follow the same procedure.

alpha(VocabularyB_L1production[,-1], warnings=FALSE)

```

```{r}
# Vocabulary B (L2 production)

alpha(VocabularyB_L2production[,-1], warnings=FALSE)

```

These reliability analyses put out Cronbach’s α, a measure of internal
consistency of tests. It indicates whether responses are consistent
between items. Before interpreting these results, we will get to the
descriptive statistics of the two types of post-tests, which the
reliability analyses are in regard to.

## Accuracy

```{r}
# To investigate accuracy, we first introduce our dataset as the variable dat.acc and load the dplyr library. In accordance with the previous data imports, we are using the here package in this case as well: 

dat.acc<-read.csv(file = here("data", "dataset1_ssla_20210313.csv"), header=T)

library(dplyr)

```

```{r}
## L1 production test
# L2 -> L1

# This code chunk, referring to L2 -> L1 of the L1 production set, processes the collected results for each participant — their ID, how many items they answered, and how many they got right — and organizes them into a clean table. Therefore, it gives us the core numbers necessary to describe and analyze accuracy. We want to take time to explain this chunk of code in detail. 


#L2→L1 (L1 production test)
ids<-data.frame(unique(dat.acc$ID))
names(ids) <- ("id")
z<-ids$id
Score<-c()
IDes<-c()
try<-c()
for (i in z){
  dat.acc%>%
    dplyr::filter(ID == i, Condition=="L2L1", Test=="L1 Production")%>%
    dplyr::select(Answer)-> acc_recT
  a<-as.vector(unlist(acc_recT))
  b<-sum(a)
  c<-length(a)
  Score<-c(Score, b)
  IDes<-c(IDes, i)
  try<-c(try,c)
}

# The first line of code takes unique IDs from dat.acc and wraps them into a data frame called "ids". The column is then named "id" using the names() function. In the next step, that column is extracted as a vector, meaning that z is a vector of unique IDs. Further, a for loop is used to iterate over elements of this vector z and assigning the IDs to the variable "i". Inside this loop, for each i (a unique ID) the data is filtered for that participant under certain conditions and then the Answer column is selected. The result is stored as the object acc_recT, which is further converted into a vector a. With b and c, the processed answers are computed and lastly, these results are appended into three vectors Score, IDes, and try. 

accu_L2L1_L1Pro<-data.frame(IDes,try, Score)
names(accu_L2L1_L1Pro)<-c("ID", "Try", "Score")
accu_L2L1_L1Pro

# In the last part, the three vectors built before are combined into a final data frame, where each vector becomes a column in a table, each row corresponding to one participant. These columns are renamed and the table is printed. If we want to properly see the table outside of the console, we can use the View() function:

View(accu_L2L1_L1Pro)

```

```{r}
#L1→L2 (L1 production test)

ids<-data.frame(unique(dat.acc$ID))
names(ids) <- ("id")
z<-ids$id
Score<-c()
IDes<-c()
try<-c()
for (i in z){
  dat.acc%>%
    dplyr::filter(ID == i, Condition=="L1L2", Test=="L1 Production")%>%
    dplyr::select(Answer)-> acc_recT
  a<-as.vector(unlist(acc_recT))
  b<-sum(a)
  c<-length(a)
  Score<-c(Score, b)
  IDes<-c(IDes, i)
  try<-c(try,c)
}

accu_L1L2_L1Pro<-data.frame(IDes,try, Score)
names(accu_L1L2_L1Pro)<-c("ID", "Try", "Score")
accu_L1L2_L1Pro
```

```{r}
# L1 production

# To provide descriptive statistics, we now want to use the describe() function on the Score column, which returns a rich set of stats.

#L2 → L1 learning
describe(accu_L2L1_L1Pro$Score)

#L1 → L2 learning
describe(accu_L1L2_L1Pro$Score)

# Plot (L1 production)

# To visualize this, we want to create a boxplot comparing the two learning directions. For this, the beeswarm package has to be installed and loaded:

# install.packages("beeswarm")

library(beeswarm)

# For this plot, we want to assign a data frame L1pro that contains the scores from both learning directions in the L1 production test. After changing the names of the columns to how we want them to appear on the x-axis, we create a side-by-side boxplot for the learning conditions. Finally, we add the beeswarm() function specifying add=T, which lets the individual scores appear as jittered dots that don't overlap.

L1pro<-data.frame(accu_L2L1_L1Pro$Score,accu_L1L2_L1Pro$Score)
names(L1pro)<-c("L2→L1 learning","L1→L2 learning")
boxplot(L1pro,col="grey91", outline = T)
beeswarm(L1pro,add=T)
```

*Interpretation here (whiskers blabla) also or only in the end with
tables?*

```{r}
## L2 production test
# L2 -> L1

# This chunk of code follows the same steps as before with the L1 production set, using L2 scores.

#L2→L1 (L2 Production test)
ids<-data.frame(unique(dat.acc$ID))
names(ids) <- ("id")
z<-ids$id
Score<-c()
IDes<-c()
try<-c()
for (i in z){
  dat.acc%>%
    dplyr::filter(ID == i, Condition=="L2L1", Test=="L2 Production")%>%
    dplyr::select(Answer)-> acc_proT
  a<-as.vector(unlist(acc_proT))
  b<-sum(a)
  c<-length(a)
  Score<-c(Score, b)
  IDes<-c(IDes, i)
  try<-c(try,c)
}

accu_L2L1_L2Pro<-data.frame(IDes,try, Score)
names(accu_L2L1_L2Pro)<-c("ID", "Try", "Score")
accu_L2L1_L2Pro
```

```{r}
## L2 production test
# L1 -> L2

#L1→L2 (L2 Production test)
ids<-data.frame(unique(dat.acc$ID))
names(ids) <- ("id")
z<-ids$id
Score<-c()
IDes<-c()
try<-c()
for (i in z){
  dat.acc%>%
    dplyr::filter(ID == i, Condition=="L1L2", Test=="L2 Production")%>%
    dplyr::select(Answer)-> acc_proT
  a<-as.vector(unlist(acc_proT))
  b<-sum(a)
  c<-length(a)
  Score<-c(Score, b)
  IDes<-c(IDes, i)
  try<-c(try,c)
}

accu_L1L2_L2Pro<-data.frame(IDes,try, Score)
names(accu_L1L2_L2Pro)<-c("ID", "Try", "Score")
accu_L1L2_L2Pro
```

```{r}
# L2 production

# In this chunk of code, we want to provide descriptive statistics for L2 production test as well and visualize them in a similar boxplot.

# L2 -> L1 learning

describe(accu_L2L1_L2Pro$Score)

# L1 -> L2 learning

describe(accu_L1L2_L2Pro$Score)

# As with L1, we create a boxplot comparing the two learning directions in L2 production using the beeswarm package.

#Plot
L2pro<-data.frame(accu_L2L1_L2Pro$Score,accu_L1L2_L2Pro$Score)
names(L2pro)<-c("L2→L1 learning","L1→L2 learning")
boxplot(L2pro,col="grey91", outline = T)
beeswarm(L2pro,add=T)

```

```{r}
# Summarized results of descriptive statistics

# In this chunk, we want to create tables that display the summarized results of descriptive statistics, similar to the tables used in the paper (p. 1126).

# First, we need to load the knitr and kableExtra packages.

library(knitr)
library(kableExtra)

# Next, we want to assign a variable that contains the scores for both data sets (L1 and L2 production) and use the describe() function to get all the important measurements.

descriptive_stats_tests <- data.frame(L1pro, L2pro) |> 
  describe()

# In keeping with the table in the paper, the first two columns (number of observations n = 28, and vars) are removed. Also, the rows are renamed in a more readable way.

descriptive_stats_tests_trimmed <- descriptive_stats_tests |> 
  select(-n, -vars, -trimmed, -mad, -range, -se)

rownames(descriptive_stats_tests_trimmed) <- c("L2 → L1 (L1pro)", "L1 → L2 (L1pro)", "L2 → L1 (L2pro)", "L1 → L2 (L2pro)")

# Now we want to display the results in a clean, formatted table.

kable(descriptive_stats_tests_trimmed, 
      caption = "Descriptive Statistics for Test Scores",
      digits = 2) |> 
  pack_rows(index = c("L1 production test" = 2, "L2 production test" = 2)) |> 
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover"))


#Interpretation: *We want to associate the results of our analysis here with the interpretation in the study. As we can see in the results of the reliability analysis, which are also displayed in a clean table in the paper (see p.1126), alpha coefficients range from .73 to .84, showing adequate reliability of all the tests. On the same page in the paper (see Table 4), the descriptive statistics of the two types of post-tests provided here are summarized in a table.*
```

```{r}
---
title: "Example"
format:
  html:
    df-print: kable
---

## example kable


mtcars |> head()
dim(mtcars)
```

# Effects of Learning Condition (Research Question 1)

```{r}
##Test Type & Learning Direction
# To test RQ1, we fit a logistic mixed-effects regression model predicting accuracy (Answer) from Test, Condition, and their interaction.

#First we install and load the packages we need, these seem to be from an older Rstudio version but they still work just fine!

# install.packages("lme4", discrepancies = TRUE)
# install.packages("effects", discrepancies = TRUE)
# install.packages("emmeans", discrepancies = TRUE)
# install.packages("phia", discrepancies = TRUE)
library(lme4) ##leading required package:Matrix
library(effects)
library(emmeans)
library(phia)


#Model with interaction
fit1<-glmer(Answer~Test+Condition+(1|ID)+(1|ItemID),family=binomial, data=dat, glmerControl(optimizer="bobyqa"))

summary(fit1)

#glmer() fits a generalized linear mixed-effects model
#Answer is a binary outcome 
#Test and Condition are fixed effects
#(1|ID) and (1|ItemID) are random intercepts for participants and items
```

# Effects of Learning Directions and L2 Proficiency (Research Question 2)

To answer the second research question: How does L2 proficiency
influence the effects of L2 to L1 and L1 to L2 learning? (Hypothesis:
<<<<<<< Updated upstream
effect of learning direction depends on Learner's L2 proficiency)...

=======
effect of learning direction depends on Learner's L2 proficiency) two
models were applied to explore the influence of L2 proficiency on the
two types of learning.

The paper reports that the advantage flips by proficiency level
(lower-proficiency learners tend to benefit more from L2-\>L1, higher
proficiency from L1-\>L2).

The packages that are used here include dplyr for the function filter(),
lme4 for the function glmer(), effects for the function allEffects(),
and phia, for the function testInteractions().

##L1 Production test

## With a second model the scores of the L1 production test were analyzed. This seccond model contained Learning Condition and Vocabulary Size (English proficiency) as explanatory variables and Accuracy of the L1 production test as the response variable (Terai et al. 2021 : 1127). Here the authors analyzed the data with interaction and without interaction, to find out the AIC, p and z scores there are a few steps we need to take.

>>>>>>> Stashed changes
```{r}
##L1 Production test

dat1<-read.csv(file = here("data", "dataset1_ssla_20210313.csv"), header=T)

dat1.L1<-filter(dat1, Test=="L1 Production")

<<<<<<< Updated upstream
=======
#Make the categorical factors factorial: this means qualitative data is encoded into numeric data so that we can work with it and use the data for statistical analysis.. "condition" also encodes learning direction. The as.factor() function is used to convert a vector into a factor, which is a data type specifically designed for categorical data. It is essential to use factors for statistical data analysis such as an ANOVA or a regression which we will be doing in a later step. At this point, we need factors for a summary of our data.
dat1.L1$Condition<-as.factor(dat1.L1$Condition)

  
#In the next step we change our coding so the variables are correct and not still working with the data from previous tests. 
#The function contr.treatment() is used to create contrast matrices for categorical variables in regression models. It is the default contrast coding method in R for unordered factors. This way a baseline/reference level is assigned and then it compares all the other levels to this baseline/reference.
c<-contr.treatment(2)


#The matrix() function creates matrices, which are two-dimensioal data structures where all elements must be of the same type (numeric, character, logical...). ncol=1 is the Number of columns.
my.coding<-matrix(rep(1/2,2,ncol=1))

#In this next step... 
my.simple<-c-my.coding

#The print() function can be used to display the value of an object or expression in the console. It can be customized for different object classes. In our case it prints out what we have assigned to my.simple, this shows...? Our Matrix??
print(my.simple)


#contr.treatment(2) starts with treatment coding(?) for a 2-level factor, and then the next two lines subtract a column of 0.5s, creating a simple (meaning centered) contrast:
##  2
## 0.5
##-0.5

```

```{r}
##makes main effects easier to interpret and reduces collinearity in interaction models (so wie ich es verstanden habe????)
#The function contrasts() in R specifies or even retrieves the contrast coding for a variable.
#Contrast coding is essential when working with linear models, as this can determine how how levels of a factor are represented as numeric dummy variables.
#A contrast in R is a combination of variables that allows comparison of different treatments.. (Explain more? Understand??)
contrasts(dat1.L1$Condition)<-my.simple

#Scaling the Score: Here Vocab scores (L2 proficiency measures) are converted to z-scores. The scale() function standardizes or normalizes data. It centers or scales the columns of our numeric matric/data frame. (EXPLAIN MORE)
dat1.L1$s.vocab<-scale(dat1.L1$Vocab)


#The glmer() function is provided by the lme4() package that we installed and activated (? anderes Wort ?) earlier. We use this function to fit Generalized Linear Mixed Effects Models (GLMMs). These models are extensions of generalized linear models (GLMs) that include random effects and thus allow the modeling of hierarchical or grouped data.
fit2<-glmer(Answer~s.vocab+Condition+(1|ID)+(1|ItemID), family=binomial, data=dat1.L1, glmerControl(optimizer="bobyqa"))
summary(fit2)
```

```{r}
options(digits=7)
AIC(fit2)
#This command prints AIC, a fit index (the lower the better)
```

```{r}
fit2.1<-glmer(Answer~s.vocab*Condition+(1|ID)+(1|ItemID), family=binomial, data=dat1.L1, glmerControl(optimizer="bobyqa"))
summary(fit2.1)
##addition of s.vocab:Condition which directly tests RQ2: Does the effect of learning direction depend on L2 proficiency? -> here s.vocab:Condition2 is negative and significant (-0.367, p=.009)
            
```

```{r}
confint(fit2.1)
```

```{r}
options(digits=7)
AIC(fit2.1)
```

```{r}
anova(fit2,fit2.1)
##Model comparison: AIC is lower for the interaction model; the LR test is significant, so the interaction model fits better???
```

```{r}
##Visualization of the interaction:
plot(allEffects(fit2.1), multiline=T, ci.style="bands",
    xlab="Vocabulary Size", ylab="Accuracy Rate",
    main="L1 Production", lty=c(1,2),
    rescale.axis=F, ylim = c(0,1), colors="black", asp=1)
```

```{r}
#Simple main effect
testInteractions(fit2.1, fixed="s.vocab", across="Condition")
```

##Repeat entire process for L2 Production Test ##without Interaction I
think ##hilfe

##L2 Production Test

```{r}
##Fehler? Kann die Datei wohl nicht öffnen, komisch?
dat2<-read.csv(file = here("data", "dataset1_ssla_20210313.csv"))

dat2.L2<-filter(dat2, Test=="L2 Production")

>>>>>>> Stashed changes
#Make the categorical factors factorial
dat1.L1$Condition<-as.factor(dat1.L1$Condition)
  
#Change coding
c<-contr.treatment(2)
my.coding<-matrix(rep(1/2,2,ncol=1))
my.simple<-c-my.coding
print(my.simple)

##Warning und FEHLER weil ich glaub ich die Daten nicht richtig abgespeichert habe, ich ändere das noch + ich muss hiervor das ganze Zeug (Codierung) einfügen bevor alles klappt glaube ich

```

# Conclusion

-   No overall difference in accuracy between L1 -\> L2 and L2 -\> L1
    learning (RQ1)
-   A significant interaction between learning direction and L2
    proficiency for L1 production scores (RQ2)
    -   lower-proficiency learners benefited more from L2-\>L1 learning
    -   higher-proficiency learners benefited more from L1-\>L2 learning

Statistical takeaway (maybe???): Mixed-effects logistic regression
allows us to model data with both fixed effects (e.g. condition) and
random effects (e.g. participant and item variability)
